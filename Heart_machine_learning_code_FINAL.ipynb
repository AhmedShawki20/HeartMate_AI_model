{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Import Modules"
      ],
      "metadata": {
        "id": "RCWKI4dXXOvr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pwKGqlsm36Q_"
      },
      "outputs": [],
      "source": [
        "# Prepare dataset\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import json\n",
        "# Modelling\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import KFold , cross_val_score\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.multiclass import OneVsOneClassifier\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix, recall_score\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "# Saving weights\n",
        "import joblib\n",
        "#---------------------------------------\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Prepare the Data"
      ],
      "metadata": {
        "id": "LfhY88hcXSvq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cL1SKYy26XSv"
      },
      "outputs": [],
      "source": [
        "train_data = pd.read_csv(\"/content/data_fin.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0k9IDXG-S3Xs"
      },
      "outputs": [],
      "source": [
        "train_data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XZTRHUIh9S8h"
      },
      "outputs": [],
      "source": [
        "print(train_data.describe())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9iVp6M2M9U4E"
      },
      "outputs": [],
      "source": [
        "print(train_data.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zY7QEDII9U6Z"
      },
      "outputs": [],
      "source": [
        "train_data.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Feature Engineering"
      ],
      "metadata": {
        "id": "GIBg4Z8tRam-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Check Null Data\n",
        "\n"
      ],
      "metadata": {
        "id": "vrAYiW0dRmKd"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jWJkJ5l29U9V"
      },
      "outputs": [],
      "source": [
        "print(train_data.isnull().sum())\n",
        "# no null data"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Check Missing Data"
      ],
      "metadata": {
        "id": "aoLHJSkyRzGt"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Se5XkySx9zak"
      },
      "outputs": [],
      "source": [
        "print(train_data.isna().sum())\n",
        "# no missing data"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Check Duplicated Data"
      ],
      "metadata": {
        "id": "SMoGeQu_R6Gl"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I5QB1-qshQYX"
      },
      "outputs": [],
      "source": [
        "# check for duplicated data\n",
        "duplicated = train_data.duplicated()\n",
        "print('Number of duplicated rows:', duplicated.sum())"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Exploration the Data"
      ],
      "metadata": {
        "id": "dKspNpkMSRvw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aZ8bYNLC9zu_"
      },
      "outputs": [],
      "source": [
        "sns.set()   # makes a grid"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SGKHI0Hv9z2X"
      },
      "outputs": [],
      "source": [
        "def bar_chart(feature):\n",
        "  Healthy = train_data[train_data[\"diagnose\"]==\"Healthy\"][feature].value_counts()\n",
        "  Angina = train_data[train_data[\"diagnose\"]==\"Angina\"][feature].value_counts()\n",
        "  Asthma = train_data[train_data[\"diagnose\"]==\"Asthma\"][feature].value_counts()\n",
        "  COPD = train_data[train_data[\"diagnose\"]==\"COPD\"][feature].value_counts()\n",
        "  Pneumonia = train_data[train_data[\"diagnose\"]==\"Pneumonia\"][feature].value_counts()\n",
        "  Heart_Attack = train_data[train_data[\"diagnose\"]==\"Heart Attack\"][feature].value_counts()\n",
        "  Hypertension = train_data[train_data[\"diagnose\"]==\"Hypertension\"][feature].value_counts()\n",
        "  Cardiac_arrest = train_data[train_data[\"diagnose\"]==\"Cardiac Arrest\"][feature].value_counts()\n",
        "  Arrhythmia = train_data[train_data[\"diagnose\"]==\"Arrhythmia\"][feature].value_counts()\n",
        "  Anemia = train_data[train_data[\"diagnose\"]==\"Anemia\"][feature].value_counts()\n",
        "  Cardiogenic_shock = train_data[train_data[\"diagnose\"]==\"Cardiogenic Shock\"][feature].value_counts()\n",
        "\n",
        "  # -----------------------------------------------------------------------------\n",
        "  df = pd.DataFrame([Healthy,Angina,Asthma,COPD,Pneumonia,Heart_Attack,Hypertension,Cardiac_arrest,Arrhythmia,Cardiogenic_shock])\n",
        "  df.index = ['Healthy','Angina','Asthma','COPD','Pneumonia','Heart Attack','Hypertension','Cardiac Arrest','Arrhythmia','Cardiogenic Shock']\n",
        "  df.plot(kind='bar',stacked=False,figsize=(10,5))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_SVUXpnV_qQ1"
      },
      "outputs": [],
      "source": [
        "bar_chart('sex')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kl6tufOKBYvV"
      },
      "outputs": [],
      "source": [
        "bar_chart('geneticHeartDiseases')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PtMbHhzuBY2K"
      },
      "outputs": [],
      "source": [
        "bar_chart('geneticDiabetes')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fOoaj3YLBY4g"
      },
      "outputs": [],
      "source": [
        "bar_chart('faint')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m7geQ_DiBY69"
      },
      "outputs": [],
      "source": [
        "bar_chart('sleep')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "UENOr-Nx2Pmi"
      },
      "outputs": [],
      "source": [
        "# ignoring divide error and pair plotting\n",
        "with np.errstate(divide='ignore',invalid='ignore'):\n",
        "    sns.pairplot(train_data, hue=\"diagnose\", palette=\"husl\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7mKeA8KTEX00"
      },
      "outputs": [],
      "source": [
        "fecet = sns.FacetGrid(train_data,hue='diagnose',aspect=4)\n",
        "fecet.map(sns.kdeplot,'age',fill=True)\n",
        "fecet.set(xlim=(0,train_data['age'].max()))\n",
        "fecet.add_legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4O8SD-PzEYGY"
      },
      "outputs": [],
      "source": [
        "fecet = sns.FacetGrid(train_data,hue='diagnose',aspect=4)\n",
        "fecet.map(sns.kdeplot,'HR',fill=True)\n",
        "fecet.set(xlim=(0,train_data['HR'].max()))\n",
        "fecet.add_legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fuw1ncYaEYI-"
      },
      "outputs": [],
      "source": [
        "fecet = sns.FacetGrid(train_data,hue='diagnose',aspect=4)\n",
        "fecet.map(sns.kdeplot,'HRV',fill=True)\n",
        "fecet.set(xlim=(0,train_data['HRV'].max()))\n",
        "fecet.add_legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Do8DTKrxEYLz"
      },
      "outputs": [],
      "source": [
        "fecet = sns.FacetGrid(train_data,hue='diagnose',aspect=4)\n",
        "fecet.map(sns.kdeplot,'RR',fill=True)\n",
        "fecet.set(xlim=(0,train_data['RR'].max()))\n",
        "fecet.add_legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pUhG_eBzGhOr"
      },
      "outputs": [],
      "source": [
        "fecet = sns.FacetGrid(train_data,hue='diagnose',aspect=4)\n",
        "fecet.map(sns.kdeplot,'SpO2',fill=True)\n",
        "fecet.set(xlim=(0,train_data['SpO2'].max()))\n",
        "fecet.add_legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EAcqIoKwHM4E"
      },
      "outputs": [],
      "source": [
        "fecet = sns.FacetGrid(train_data,hue='diagnose',aspect=4)\n",
        "fecet.map(sns.kdeplot,'Systolic_BP',fill=True)\n",
        "fecet.set(xlim=(0,train_data['Systolic_BP'].max()))\n",
        "fecet.add_legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GAFBoPNWJVh0"
      },
      "outputs": [],
      "source": [
        "fecet = sns.FacetGrid(train_data,hue='diagnose',aspect=4)\n",
        "fecet.map(sns.kdeplot,'Diastolic_BP',fill=True)\n",
        "fecet.set(xlim=(0,train_data['Diastolic_BP'].max()))\n",
        "fecet.add_legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cROgXcu6JV_V"
      },
      "outputs": [],
      "source": [
        "fecet = sns.FacetGrid(train_data,hue='diagnose',aspect=4)\n",
        "fecet.map(sns.kdeplot,'temperature',fill=True)\n",
        "fecet.set(xlim=(30,train_data['temperature'].max()))\n",
        "fecet.add_legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nx0azeAtHfTm"
      },
      "outputs": [],
      "source": [
        "train_data.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z6HMnV4JKT2a"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(20,20))\n",
        "sns.heatmap(train_data.corr(),annot=True,fmt='.2f')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y-Hgb_WD8fCU"
      },
      "outputs": [],
      "source": [
        "train_data.head(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Encode Categorical Variables"
      ],
      "metadata": {
        "id": "bHZhnKXhUXC-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c49r3CaF3tGi"
      },
      "outputs": [],
      "source": [
        "def encode_variables(Target_data):\n",
        "  # --------------------------------------------------------\n",
        "  # Encode the categorical data as integers\n",
        "  le = LabelEncoder()\n",
        "  # Encode sex\n",
        "  Target_data['sex'] = le.fit_transform(Target_data['sex'])\n",
        "  # Encode genetic_diabetes\n",
        "  Target_data['geneticDiabetes'] = le.fit_transform(Target_data['geneticDiabetes'])\n",
        "  # Encode genetic_heart_disease\n",
        "  Target_data['geneticHeartDiseases'] = le.fit_transform(Target_data['geneticHeartDiseases'])\n",
        "  # Encode smoker\n",
        "  Target_data['smoker'] = le.fit_transform(Target_data['smoker'])\n",
        "  # Encode faint\n",
        "  Target_data['faint'] = le.fit_transform(Target_data['faint'])\n",
        "  # Encode sleep\n",
        "  Target_data['sleep'] = le.fit_transform(Target_data['sleep'])\n",
        "\n",
        "\n",
        "def encode_diagnose(Diagnosis):\n",
        "  # Encode the categorical data as integers\n",
        "  le = LabelEncoder()\n",
        "  # Encode diagnose\n",
        "  Diagnosis['diagnose'] = le.fit_transform(Diagnosis['diagnose'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X3x6tD9O8Xv8"
      },
      "outputs": [],
      "source": [
        "train_data.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PxiXCLrR8aHf"
      },
      "outputs": [],
      "source": [
        "train_data.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "encode_variables(train_data)\n",
        "encode_diagnose(train_data)"
      ],
      "metadata": {
        "id": "O9MFxzJCa-Hx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Spliting the Data into Training and Testing sets"
      ],
      "metadata": {
        "id": "b2RSdHleVLli"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the data into training and testing sets\n",
        "x_train = train_data.drop(\"diagnose\",axis=1)\n",
        "y_train = train_data[\"diagnose\"]\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(x_train, y_train, test_size=0.20, random_state=1)"
      ],
      "metadata": {
        "id": "8oU7iETwVPjV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M0ozUJCL3fYv"
      },
      "outputs": [],
      "source": [
        "train_data.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Traning Model"
      ],
      "metadata": {
        "id": "3NavOYEAYmx9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9OwNKEU2uzjl"
      },
      "outputs": [],
      "source": [
        "# Train and evaluate a Linear Discriminant model\n",
        "lr = LinearDiscriminantAnalysis()\n",
        "lr.fit(x_train, y_train)\n",
        "y_pred = lr.predict(x_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "# storing recall_score for later comparision\n",
        "lr_recall = round(recall_score(y_test,y_pred,average='weighted'),3)\n",
        "print (classification_report(y_test, y_pred, labels=None, target_names=None, sample_weight=None, digits=3, output_dict=False))\n",
        "acc = accuracy_score(y_test, y_pred)\n",
        "print ( \"Linear Discriminant Accuracy: %.3f\" % acc)\n",
        "print (\"\\n\")\n",
        "# --------------------------------------------------------------------------\n",
        "# Train and evaluate a Logistic Regression model\n",
        "lr = LogisticRegression(max_iter=10000)\n",
        "lr.fit(x_train, y_train)\n",
        "y_pred = lr.predict(x_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "# storing recall_score for later comparision\n",
        "lr_recall = round(recall_score(y_test,y_pred,average='weighted'),3)\n",
        "print (classification_report(y_test, y_pred, labels=None, target_names=None, sample_weight=None, digits=3, output_dict=False))\n",
        "acc = accuracy_score(y_test, y_pred)\n",
        "print ( \"Logistic Regression Accuracy: %.3f\" % acc)\n",
        "print (\"\\n\")\n",
        "# --------------------------------------------------------------------------\n",
        "# Train and evaluate a Decision Tree model\n",
        "dt = DecisionTreeClassifier()\n",
        "dt.fit(x_train, y_train)\n",
        "y_pred = dt.predict(x_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "# storing recall_score for later comparision\n",
        "dt_recall = round(recall_score(y_test,y_pred,average='weighted'),3)\n",
        "print (classification_report(y_test, y_pred, labels=None, target_names=None, sample_weight=None, digits=3, output_dict=False))\n",
        "acc = accuracy_score(y_test, y_pred)\n",
        "print ( \"Decision Tree Accuracy: %.3f\" % acc)\n",
        "print (\"\\n\")\n",
        "# --------------------------------------------------------------------------\n",
        "# Train and evaluate a Random Forest model\n",
        "rf = RandomForestClassifier()\n",
        "rf.fit(x_train, y_train)\n",
        "y_pred = rf.predict(x_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "# storing recall_score for later comparision\n",
        "rf_recall = round(recall_score(y_test,y_pred,average='weighted'),3)\n",
        "print (classification_report(y_test, y_pred, labels=None, target_names=None, sample_weight=None, digits=3, output_dict=False))\n",
        "acc = accuracy_score(y_test, y_pred)\n",
        "print ( \"Random Forest Accuracy: %.3f\" % acc)\n",
        "print (\"\\n\")\n",
        "# --------------------------------------------------------------------------\n",
        "# Train and evaluate a K-Nearest Neighbors model\n",
        "knn = KNeighborsClassifier()\n",
        "knn.fit(x_train, y_train)\n",
        "y_pred = knn.predict(x_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "# storing recall_score for later comparision\n",
        "knn_recall = round(recall_score(y_test,y_pred,average='weighted'),3)\n",
        "print (classification_report(y_test, y_pred, labels=None, target_names=None, sample_weight=None, digits=3, output_dict=False))\n",
        "acc = accuracy_score(y_test, y_pred)\n",
        "print ( \"K-Nearest Neighbors Accuracy: %.3f\" % acc)\n",
        "print (\"\\n\")\n",
        "# --------------------------------------------------------------------------\n",
        "# Train and evaluate a Support Vector Machine model\n",
        "svc = SVC()\n",
        "svc.fit(x_train, y_train)\n",
        "y_pred = svc.predict(x_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "# storing recall_score for later comparision\n",
        "svc_recall = round(recall_score(y_test,y_pred,average='weighted'),3)\n",
        "print (classification_report(y_test, y_pred, labels=None, target_names=None, sample_weight=None, digits=3, output_dict=False))\n",
        "acc = accuracy_score(y_test, y_pred)\n",
        "print ( \"Support Vector Machine Accuracy: %.3f\" % acc)\n",
        "print (\"\\n\")\n",
        "# --------------------------------------------------------------------------\n",
        "# Train and evaluate a Naive Bayes model\n",
        "gnb = GaussianNB()\n",
        "gnb.fit(x_train, y_train)\n",
        "y_pred = gnb.predict(x_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "# storing recall_score for later comparision\n",
        "gnb_recall = round(recall_score(y_test,y_pred,average='weighted'),3)\n",
        "print (classification_report(y_test, y_pred, labels=None, target_names=None, sample_weight=None, digits=3, output_dict=False))\n",
        "acc = accuracy_score(y_test, y_pred)\n",
        "print ( \"Naive Bayes Accuracy: %.3f\" % acc)\n",
        "print (\"\\n\")\n",
        "# --------------------------------------------------------------------------\n",
        "# Train and evaluate a Multi-Layer Perceptron model\n",
        "mlp = MLPClassifier(max_iter=10000)\n",
        "mlp.fit(x_train, y_train)\n",
        "y_pred = mlp.predict(x_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "# ---   ---   ---\n",
        "# storing recall_score for later comparision\n",
        "mlp_recall = round(recall_score(y_test,y_pred,average='weighted'),3)\n",
        "print (classification_report(y_test, y_pred, labels=None, target_names=None, sample_weight=None, digits=3, output_dict=False))\n",
        "acc = accuracy_score(y_test, y_pred)\n",
        "print ( \"Multi-Layer Perceptron Accuracy: %.3f\" % acc)\n",
        "# --------------------------------------------------------------------------\n",
        "# Train and evaluate a Gradient Boosting Classifier model\n",
        "gbc = GradientBoostingClassifier()\n",
        "gbc.fit(x_train, y_train)\n",
        "y_pred = gbc.predict(x_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "# ---   ---   ---\n",
        "# storing recall_score for later comparision\n",
        "gbc_recall = round(recall_score(y_test,y_pred,average='weighted'),3)\n",
        "print (classification_report(y_test, y_pred, labels=None, target_names=None, sample_weight=None, digits=3, output_dict=False))\n",
        "acc = accuracy_score(y_test, y_pred)\n",
        "print ( \"Gradient Boosting Classifier Accuracy: %.3f\" % acc)\n",
        "# --------------------------------------------------------------------------\n",
        "print(\"\\n\\n\")\n",
        "# train using Cross Val Score\n",
        "# Spot Check Algorithms\n",
        "models = []\n",
        "models.append(('LR Logistic Regression Accuracy', LogisticRegression(solver='liblinear', multi_class='ovr')))\n",
        "models.append(('LDA Linear Discriminat Analysis Accuracy:', LinearDiscriminantAnalysis()))\n",
        "models.append(('KNN Accurcy:', KNeighborsClassifier()))\n",
        "models.append(('CenterART Decision Tree Accuracy:', DecisionTreeClassifier()))\n",
        "models.append(('NB Naive Bayes Accuracy:', GaussianNB()))\n",
        "models.append(('Multi-Layer Perceptron Accuracy:', MLPClassifier(max_iter=10000)))\n",
        "models.append(('Random Forest Accuracy:', RandomForestClassifier()))\n",
        "models.append(('SVM', SVC(gamma='auto')))\n",
        "models.append(('GradientBoostingClassifier Accuracy:',GradientBoostingClassifier()))\n",
        "# evaluate each model in turn\n",
        "results = []\n",
        "names = []\n",
        "for name, model in models:\n",
        "\tkfold = StratifiedKFold(n_splits=10, random_state=1, shuffle=True)\n",
        "\tcv_results = cross_val_score(model, x_train, y_train, cv=kfold, scoring='accuracy')\n",
        "\tresults.append(cv_results)\n",
        "\tnames.append(name)\n",
        "\tprint('%s: %f (%f)' % (name, cv_results.mean(), cv_results.std()))\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TWSSs83EY5w2"
      },
      "source": [
        "### Save the weights as JOBLIB"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IyTbjpJGY5w3"
      },
      "outputs": [],
      "source": [
        "filename = 'heart_model_KNN.joblib'\n",
        "joblib.dump(knn, open(filename, 'wb'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OaaF5qVyY5w3"
      },
      "outputs": [],
      "source": [
        "loaded_model = joblib.load(open(filename, 'rb'))\n",
        "model_pred = loaded_model.predict(x_test)\n",
        "# storing recall_score for later comparision\n",
        "model_recall = round(recall_score(y_test,model_pred,average='weighted'),3)\n",
        "print (classification_report(y_test, model_pred, labels=None, target_names=None, sample_weight=None, digits=3, output_dict=False))\n",
        "acc = accuracy_score(y_test, model_pred)\n",
        "print (\"Accuracy: %.3f\" % acc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oau0RJn7Y5w4"
      },
      "outputs": [],
      "source": [
        "filename = 'heart_model_LogisticRegression.joblib'\n",
        "joblib.dump(lr, open(filename, 'wb'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M0flo3shY5w4"
      },
      "outputs": [],
      "source": [
        "loaded_model = joblib.load(open(filename, 'rb'))\n",
        "model_pred = loaded_model.predict(x_test)\n",
        "# storing recall_score for later comparision\n",
        "model_recall = round(recall_score(y_test,model_pred,average='weighted'),3)\n",
        "print (classification_report(y_test, model_pred, labels=None, target_names=None, sample_weight=None, digits=3, output_dict=False))\n",
        "acc = accuracy_score(y_test, model_pred)\n",
        "print (\"Accuracy: %.3f\" % acc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6q9Uvry0Y5w5"
      },
      "outputs": [],
      "source": [
        "filename = 'heart_model_DecisionTree.joblib'\n",
        "joblib.dump(dt, open(filename, 'wb'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s49mA4zyY5w5"
      },
      "outputs": [],
      "source": [
        "loaded_model = joblib.load(open(filename, 'rb'))\n",
        "model_pred = loaded_model.predict(x_test)\n",
        "# storing recall_score for later comparision\n",
        "model_recall = round(recall_score(y_test,model_pred,average='weighted'),3)\n",
        "print (classification_report(y_test, model_pred, labels=None, target_names=None, sample_weight=None, digits=3, output_dict=False))\n",
        "acc = accuracy_score(y_test, model_pred)\n",
        "print (\"Accuracy: %.3f\" % acc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lgo9Cul1Y5w6"
      },
      "outputs": [],
      "source": [
        "filename = 'heart_model_RandomForest.joblib'\n",
        "joblib.dump(rf, open(filename, 'wb'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NTgeaXAVY5w6"
      },
      "outputs": [],
      "source": [
        "loaded_model = joblib.load(open(filename, 'rb'))\n",
        "model_pred = loaded_model.predict(x_test)\n",
        "# storing recall_score for later comparision\n",
        "model_recall = round(recall_score(y_test,model_pred,average='weighted'),3)\n",
        "print (classification_report(y_test, model_pred, labels=None, target_names=None, sample_weight=None, digits=3, output_dict=False))\n",
        "acc = accuracy_score(y_test, model_pred)\n",
        "print (\"Accuracy: %.3f\" % acc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wrOrAVPlY5w6"
      },
      "outputs": [],
      "source": [
        "filename = 'heart_model_SVM.joblib'\n",
        "joblib.dump(svc, open(filename, 'wb'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-c9uw0H6Y5w6"
      },
      "outputs": [],
      "source": [
        "loaded_model = joblib.load(open(filename, 'rb'))\n",
        "model_pred = loaded_model.predict(x_test)\n",
        "# storing recall_score for later comparision\n",
        "model_recall = round(recall_score(y_test,model_pred,average='weighted'),3)\n",
        "print (classification_report(y_test, model_pred, labels=None, target_names=None, sample_weight=None, digits=3, output_dict=False))\n",
        "acc = accuracy_score(y_test, model_pred)\n",
        "print (\"Accuracy: %.3f\" % acc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mA3vlUArY5w7"
      },
      "outputs": [],
      "source": [
        "filename = 'heart_model_GaussianNB.joblib'\n",
        "joblib.dump(gnb, open(filename, 'wb'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NqfwZMawY5w7"
      },
      "outputs": [],
      "source": [
        "loaded_model = joblib.load(open(filename, 'rb'))\n",
        "model_pred = loaded_model.predict(x_test)\n",
        "# storing recall_score for later comparision\n",
        "model_recall = round(recall_score(y_test,model_pred,average='weighted'),3)\n",
        "print (classification_report(y_test, model_pred, labels=None, target_names=None, sample_weight=None, digits=3, output_dict=False))\n",
        "acc = accuracy_score(y_test, model_pred)\n",
        "print (\"Accuracy: %.3f\" % acc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1EpCXTI2Y5w7"
      },
      "outputs": [],
      "source": [
        "filename = 'heart_model_Multi_LayerPerceptron.joblib'\n",
        "joblib.dump(mlp, open(filename, 'wb'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-Hl2AsZIY5w7"
      },
      "outputs": [],
      "source": [
        "loaded_model = joblib.load(open(filename, 'rb'))\n",
        "model_pred = loaded_model.predict(x_test)\n",
        "# storing recall_score for later comparision\n",
        "model_recall = round(recall_score(y_test,model_pred,average='weighted'),3)\n",
        "print (classification_report(y_test, model_pred, labels=None, target_names=None, sample_weight=None, digits=3, output_dict=False))\n",
        "acc = accuracy_score(y_test, model_pred)\n",
        "print (\"Accuracy: %.3f\" % acc)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pvLCw0jKob7i"
      },
      "source": [
        "# Normalization"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "split"
      ],
      "metadata": {
        "id": "zatQ5iVvZaqF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kt7QFU1-oZe6"
      },
      "outputs": [],
      "source": [
        "x_data = train_data.drop(['diagnose'], axis=1)\n",
        "# normalization\n",
        "X = (x_data - np.min(x_data)) / (np.max(x_data) - np.min(x_data)).values\n",
        "Y = train_data['diagnose']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size = 0.2, random_state = 0)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data.head(15)"
      ],
      "metadata": {
        "id": "-FPwhtV8UfAV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training"
      ],
      "metadata": {
        "id": "ejCaqwS9Z0Fa"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jZNyMDDRtXGZ"
      },
      "outputs": [],
      "source": [
        "# Train and evaluate a Logistic Regression model\n",
        "lr = LinearDiscriminantAnalysis()\n",
        "lr.fit(x_train, y_train)\n",
        "y_pred = lr.predict(x_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "# storing recall_score for later comparision\n",
        "lr_recall = round(recall_score(y_test,y_pred,average='weighted'),3)\n",
        "print (classification_report(y_test, y_pred, labels=None, target_names=None, sample_weight=None, digits=3, output_dict=False))\n",
        "acc = accuracy_score(y_test, y_pred)\n",
        "print ( \"Linear Discriminant Accuracy: %.3f\" % acc)\n",
        "print (\"\\n\")\n",
        "# --------------------------------------------------------------------------\n",
        "# Train and evaluate a Logistic Regression model\n",
        "lr = LogisticRegression(max_iter=10000)\n",
        "lr.fit(x_train, y_train)\n",
        "y_pred = lr.predict(x_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "# storing recall_score for later comparision\n",
        "lr_recall = round(recall_score(y_test,y_pred,average='weighted'),3)\n",
        "print (classification_report(y_test, y_pred, labels=None, target_names=None, sample_weight=None, digits=3, output_dict=False))\n",
        "acc = accuracy_score(y_test, y_pred)\n",
        "print ( \"Logistic Regression Accuracy: %.3f\" % acc)\n",
        "print (\"\\n\")\n",
        "# --------------------------------------------------------------------------\n",
        "# Train and evaluate a Decision Tree model\n",
        "dt = DecisionTreeClassifier()\n",
        "dt.fit(x_train, y_train)\n",
        "y_pred = dt.predict(x_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "# storing recall_score for later comparision\n",
        "dt_recall = round(recall_score(y_test,y_pred,average='weighted'),3)\n",
        "print (classification_report(y_test, y_pred, labels=None, target_names=None, sample_weight=None, digits=3, output_dict=False))\n",
        "acc = accuracy_score(y_test, y_pred)\n",
        "print ( \"Decision Tree Accuracy: %.3f\" % acc)\n",
        "print (\"\\n\")\n",
        "# --------------------------------------------------------------------------\n",
        "# Train and evaluate a Random Forest model\n",
        "rf = RandomForestClassifier()\n",
        "rf.fit(x_train, y_train)\n",
        "y_pred = rf.predict(x_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "# storing recall_score for later comparision\n",
        "rf_recall = round(recall_score(y_test,y_pred,average='weighted'),3)\n",
        "print (classification_report(y_test, y_pred, labels=None, target_names=None, sample_weight=None, digits=3, output_dict=False))\n",
        "acc = accuracy_score(y_test, y_pred)\n",
        "print ( \"Random Forest Accuracy: %.3f\" % acc)\n",
        "print (\"\\n\")\n",
        "# --------------------------------------------------------------------------\n",
        "# Train and evaluate a K-Nearest Neighbors model\n",
        "knn = KNeighborsClassifier()\n",
        "knn.fit(x_train, y_train)\n",
        "y_pred = knn.predict(x_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "# storing recall_score for later comparision\n",
        "knn_recall = round(recall_score(y_test,y_pred,average='weighted'),3)\n",
        "print (classification_report(y_test, y_pred, labels=None, target_names=None, sample_weight=None, digits=3, output_dict=False))\n",
        "acc = accuracy_score(y_test, y_pred)\n",
        "print ( \"K-Nearest Neighbors Accuracy: %.3f\" % acc)\n",
        "print (\"\\n\")\n",
        "# --------------------------------------------------------------------------\n",
        "# Train and evaluate a Support Vector Machine model\n",
        "svc = SVC()\n",
        "svc.fit(x_train, y_train)\n",
        "y_pred = svc.predict(x_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "# storing recall_score for later comparision\n",
        "svc_recall = round(recall_score(y_test,y_pred,average='weighted'),3)\n",
        "print (classification_report(y_test, y_pred, labels=None, target_names=None, sample_weight=None, digits=3, output_dict=False))\n",
        "acc = accuracy_score(y_test, y_pred)\n",
        "print ( \"Support Vector Machine Accuracy: %.3f\" % acc)\n",
        "print (\"\\n\")\n",
        "# --------------------------------------------------------------------------\n",
        "# Train and evaluate a Naive Bayes model\n",
        "gnb = GaussianNB()\n",
        "gnb.fit(x_train, y_train)\n",
        "y_pred = gnb.predict(x_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "# storing recall_score for later comparision\n",
        "gnb_recall = round(recall_score(y_test,y_pred,average='weighted'),3)\n",
        "print (classification_report(y_test, y_pred, labels=None, target_names=None, sample_weight=None, digits=3, output_dict=False))\n",
        "acc = accuracy_score(y_test, y_pred)\n",
        "print ( \"Naive Bayes Accuracy: %.3f\" % acc)\n",
        "print (\"\\n\")\n",
        "# --------------------------------------------------------------------------\n",
        "# Train and evaluate a Multi-Layer Perceptron model\n",
        "mlp = MLPClassifier(max_iter=10000)\n",
        "mlp.fit(x_train, y_train)\n",
        "y_pred = mlp.predict(x_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "# ------\n",
        "# storing recall_score for later comparision\n",
        "mlp_recall = round(recall_score(y_test,y_pred,average='weighted'),3)\n",
        "print (classification_report(y_test, y_pred, labels=None, target_names=None, sample_weight=None, digits=3, output_dict=False))\n",
        "acc = accuracy_score(y_test, y_pred)\n",
        "print ( \"Multi-Layer Perceptron Accuracy: %.3f\" % acc)\n",
        "# ----------------------------------------------------------\n",
        "print(\"\\n\\n\")\n",
        "# train using Cross Val Score\n",
        "# Spot Check Algorithms\n",
        "models = []\n",
        "models.append(('LR Logistic Regression Accuracy', LogisticRegression(solver='liblinear', multi_class='ovr')))\n",
        "models.append(('LDA Linear Discriminat Analysis Accuracy:', LinearDiscriminantAnalysis()))\n",
        "models.append(('KNN Accurcy:', KNeighborsClassifier()))\n",
        "models.append(('CenterART Decision Tree Accuracy:', DecisionTreeClassifier()))\n",
        "models.append(('NB Naive Bayes Accuracy:', GaussianNB()))\n",
        "models.append(('Multi-Layer Perceptron Accuracy:', MLPClassifier(max_iter=10000)))\n",
        "models.append(('Random Forest Accuracy:', RandomForestClassifier()))\n",
        "models.append(('SVM', SVC(gamma='auto')))\n",
        "# evaluate each model in turn\n",
        "results = []\n",
        "names = []\n",
        "for name, model in models:\n",
        "\tkfold = StratifiedKFold(n_splits=10, random_state=1, shuffle=True)\n",
        "\tcv_results = cross_val_score(model, x_train, y_train, cv=kfold, scoring='accuracy')\n",
        "\tresults.append(cv_results)\n",
        "\tnames.append(name)\n",
        "\tprint('%s: %f (%f)' % (name, cv_results.mean(), cv_results.std()))\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jHVe11jdsqdy"
      },
      "source": [
        "### Saving weights as Joblib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "90d22442"
      },
      "outputs": [],
      "source": [
        "filename = 'heart_model_KNN_normalization.joblib'\n",
        "joblib.dump(knn, open(filename, 'wb'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "382c8fb0"
      },
      "outputs": [],
      "source": [
        "loaded_model = joblib.load(open(filename, 'rb'))\n",
        "model_pred = loaded_model.predict(x_test)\n",
        "# storing recall_score for later comparision\n",
        "model_recall = round(recall_score(y_test,model_pred,average='weighted'),3)\n",
        "print (classification_report(y_test, model_pred, labels=None, target_names=None, sample_weight=None, digits=3, output_dict=False))\n",
        "acc = accuracy_score(y_test, model_pred)\n",
        "print (\"Accuracy: %.3f\" % acc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vlayPg0Z5myY"
      },
      "outputs": [],
      "source": [
        "filename = 'heart_model_LogisticRegression_normalization.joblib'\n",
        "joblib.dump(lr, open(filename, 'wb'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xK58T4vzsWSz"
      },
      "outputs": [],
      "source": [
        "loaded_model = joblib.load(open(filename, 'rb'))\n",
        "model_pred = loaded_model.predict(x_test)\n",
        "# storing recall_score for later comparision\n",
        "model_recall = round(recall_score(y_test,model_pred,average='weighted'),3)\n",
        "print (classification_report(y_test, model_pred, labels=None, target_names=None, sample_weight=None, digits=3, output_dict=False))\n",
        "acc = accuracy_score(y_test, model_pred)\n",
        "print (\"Accuracy: %.3f\" % acc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IFAWw2Mu5mk2"
      },
      "outputs": [],
      "source": [
        "filename = 'heart_model_DecisionTree_normalization.joblib'\n",
        "joblib.dump(dt, open(filename, 'wb'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WJM4LQCpsWxy"
      },
      "outputs": [],
      "source": [
        "loaded_model = joblib.load(open(filename, 'rb'))\n",
        "model_pred = loaded_model.predict(x_test)\n",
        "# storing recall_score for later comparision\n",
        "model_recall = round(recall_score(y_test,model_pred,average='weighted'),3)\n",
        "print (classification_report(y_test, model_pred, labels=None, target_names=None, sample_weight=None, digits=3, output_dict=False))\n",
        "acc = accuracy_score(y_test, model_pred)\n",
        "print (\"Accuracy: %.3f\" % acc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ybQtqemK5miD"
      },
      "outputs": [],
      "source": [
        "filename = 'heart_model_RandomForest_normalization.joblib'\n",
        "joblib.dump(rf, open(filename, 'wb'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pB6swaHlsXZH"
      },
      "outputs": [],
      "source": [
        "loaded_model = joblib.load(open(filename, 'rb'))\n",
        "model_pred = loaded_model.predict(x_test)\n",
        "# storing recall_score for later comparision\n",
        "model_recall = round(recall_score(y_test,model_pred,average='weighted'),3)\n",
        "print (classification_report(y_test, model_pred, labels=None, target_names=None, sample_weight=None, digits=3, output_dict=False))\n",
        "acc = accuracy_score(y_test, model_pred)\n",
        "print (\"Accuracy: %.3f\" % acc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SElV98U55me5"
      },
      "outputs": [],
      "source": [
        "filename = 'heart_model_SVM_normalization.joblib'\n",
        "joblib.dump(svc, open(filename, 'wb'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jCE_VkaCsXxJ"
      },
      "outputs": [],
      "source": [
        "loaded_model = joblib.load(open(filename, 'rb'))\n",
        "model_pred = loaded_model.predict(x_test)\n",
        "# storing recall_score for later comparision\n",
        "model_recall = round(recall_score(y_test,model_pred,average='weighted'),3)\n",
        "print (classification_report(y_test, model_pred, labels=None, target_names=None, sample_weight=None, digits=3, output_dict=False))\n",
        "acc = accuracy_score(y_test, model_pred)\n",
        "print (\"Accuracy: %.3f\" % acc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qpZcQNmv5mcd"
      },
      "outputs": [],
      "source": [
        "filename = 'heart_model_GaussianNB_normalization.joblib'\n",
        "joblib.dump(gnb, open(filename, 'wb'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FNy9QQa1sYGZ"
      },
      "outputs": [],
      "source": [
        "loaded_model = joblib.load(open(filename, 'rb'))\n",
        "model_pred = loaded_model.predict(x_test)\n",
        "# storing recall_score for later comparision\n",
        "model_recall = round(recall_score(y_test,model_pred,average='weighted'),3)\n",
        "print (classification_report(y_test, model_pred, labels=None, target_names=None, sample_weight=None, digits=3, output_dict=False))\n",
        "acc = accuracy_score(y_test, model_pred)\n",
        "print (\"Accuracy: %.3f\" % acc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EQ3jj06e5maZ"
      },
      "outputs": [],
      "source": [
        "filename = 'heart_model_Multi_LayerPerceptron_normalization.joblib'\n",
        "joblib.dump(mlp, open(filename, 'wb'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zS7bHzcasYer"
      },
      "outputs": [],
      "source": [
        "loaded_model = joblib.load(open(filename, 'rb'))\n",
        "model_pred = loaded_model.predict(x_test)\n",
        "# storing recall_score for later comparision\n",
        "model_recall = round(recall_score(y_test,model_pred,average='weighted'),3)\n",
        "print (classification_report(y_test, model_pred, labels=None, target_names=None, sample_weight=None, digits=3, output_dict=False))\n",
        "acc = accuracy_score(y_test, model_pred)\n",
        "print (\"Accuracy: %.3f\" % acc)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aXuJ1uk3brlW"
      },
      "source": [
        "# Predict model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kuWpuk6rh_Mb"
      },
      "outputs": [],
      "source": [
        "model_pred = loaded_model.predict(x_test[0:7])\n",
        "print(model_pred)\n",
        "print(y_test[0:7])\n",
        "print(train_data.head(35))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "ejCaqwS9Z0Fa",
        "ZfFR0roVGUe1"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}